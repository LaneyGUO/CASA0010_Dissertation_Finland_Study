{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson's Chi-squared Test**\n",
    "\n",
    "*Categorical variable independence test between percolation clusters & poi clusters/affinity clusters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Independence tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 403921 entries, 0 to 403920\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   gid_10                  403921 non-null  object \n",
      " 1   percolation_cluster_id  323256 non-null  float64\n",
      " 2   poi_cluster_id          63548 non-null   float64\n",
      " 3   affinity_cluster_id     82471 non-null   float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 12.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge all cluster numbers\n",
    "\n",
    "percolation_df = pd.read_csv('../2-percolation/hexagon_get_percolation_cluster_id/percolation_cluster_id.csv')\n",
    "poi_clustering_df = pd.read_csv('../3-profile_clustering/1-poi_clustering/step4-clustering&optimal_cluster_num/poi_clustering_results.csv')\n",
    "affinity_clustering_df = pd.read_csv('../3-profile_clustering/2-affinity_clustering/step2-clustering/affinity_clustering_results.csv')\n",
    "\n",
    "\n",
    "percolation_df = percolation_df[['gid_10', 'percolation_cluster_id']]\n",
    "poi_clustering_df = poi_clustering_df[['gid_10', 'poi_cluster_id']]\n",
    "affinity_clustering_df = affinity_clustering_df[['gid_10', 'affinity_cluster_id']]\n",
    "\n",
    "\n",
    "merged_df = pd.merge(percolation_df, poi_clustering_df, on='gid_10', how='outer')\n",
    "merged_df = pd.merge(merged_df, affinity_clustering_df, on='gid_10', how='outer')\n",
    "\n",
    "\n",
    "print(merged_df.info())\n",
    "\n",
    "\n",
    "merged_df.to_csv('./all_clusters.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gid_10</th>\n",
       "      <th>percolation_cluster_id</th>\n",
       "      <th>poi_cluster_id</th>\n",
       "      <th>affinity_cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a01261212affff</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8a012612175ffff</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8a0126182447fff</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8a0126182467fff</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8a012618246ffff</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gid_10  percolation_cluster_id  poi_cluster_id  \\\n",
       "0  8a01261212affff                 13696.0             NaN   \n",
       "1  8a012612175ffff                 13696.0             NaN   \n",
       "2  8a0126182447fff                 13696.0             NaN   \n",
       "3  8a0126182467fff                 13696.0             NaN   \n",
       "4  8a012618246ffff                 13696.0             NaN   \n",
       "\n",
       "   affinity_cluster_id  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Read the merged data\n",
    "df = pd.read_csv('./all_clusters.csv')\n",
    "\n",
    "# Calculate chi-squared test results between percolation_cluster_id and other clusters, excluding rows with missing values, and check if the sample size for percolation_cluster_id is 50 or more\n",
    "def calculate_chi2_percolation(var1, var2, df):\n",
    "    # Drop rows with missing values\n",
    "    df_clean = df.dropna(subset=[var1, var2])\n",
    "\n",
    "    # Keep only rows where the sample size for percolation_cluster_id is 10 or more\n",
    "    df_filtered = df_clean[df_clean.groupby('percolation_cluster_id')['percolation_cluster_id'].transform('count') >= 10]\n",
    "\n",
    "    # If there are not enough samples after filtering, skip this test\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No percolation_cluster_id has 10 or more instances for the test between {var1} and {var2}. Skipping this test.\")\n",
    "        return None\n",
    "\n",
    "    # Construct a contingency table\n",
    "    contingency_table = pd.crosstab(df_filtered[var1], df_filtered[var2])\n",
    "\n",
    "    # Perform chi-squared test\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "    # Determine significance\n",
    "    significance = \"Significant\" if p < 0.05 else \"Not Significant\"\n",
    "\n",
    "    # Output the test result\n",
    "    print(f\"Chi-squared test between {var1} and {var2}\")\n",
    "    print(f\"Chi2 statistic: {chi2:.4f}, p-value: {p:.4f}, Degrees of Freedom: {dof}\")\n",
    "    if significance == \"Significant\":\n",
    "        print(f\"The relationship between {var1} and {var2} is statistically significant (p < 0.05).\")\n",
    "    else:\n",
    "        print(f\"The relationship between {var1} and {var2} is not statistically significant (p >= 0.05).\")\n",
    "    print(\"\\n\")  # Separate the output of different tests\n",
    "\n",
    "    # Return the result as a dictionary\n",
    "    return {\n",
    "        \"Test\": f\"{var1} vs {var2}\",\n",
    "        \"Chi2 Statistic\": chi2,\n",
    "        \"p-value\": p,\n",
    "        \"Degrees of Freedom\": dof,\n",
    "        \"Significance\": significance\n",
    "    }\n",
    "\n",
    "# Calculate chi-squared test results between poi_cluster_id and affinity_cluster_id\n",
    "def calculate_chi2_general(var1, var2, df):\n",
    "    # Drop rows with missing values\n",
    "    df_clean = df.dropna(subset=[var1, var2])\n",
    "\n",
    "    # Construct a contingency table\n",
    "    contingency_table = pd.crosstab(df_clean[var1], df_clean[var2])\n",
    "\n",
    "    # Perform chi-squared test\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "    # Determine significance\n",
    "    significance = \"Significant\" if p < 0.05 else \"Not Significant\"\n",
    "\n",
    "    # Output the test result\n",
    "    print(f\"Chi-squared test between {var1} and {var2}\")\n",
    "    print(f\"Chi2 statistic: {chi2:.4f}, p-value: {p:.4f}, Degrees of Freedom: {dof}\")\n",
    "    if significance == \"Significant\":\n",
    "        print(f\"The relationship between {var1} and {var2} is statistically significant (p < 0.05).\")\n",
    "    else:\n",
    "        print(f\"The relationship between {var1} and {var2} is not statistically significant (p >= 0.05).\")\n",
    "    print(\"\\n\")  # Separate the output of different tests\n",
    "\n",
    "    # Return the result as a dictionary\n",
    "    return {\n",
    "        \"Test\": f\"{var1} vs {var2}\",\n",
    "        \"Chi2 Statistic\": chi2,\n",
    "        \"p-value\": p,\n",
    "        \"Degrees of Freedom\": dof,\n",
    "        \"Significance\": significance\n",
    "    }\n",
    "\n",
    "# Calculate the results of the first two tests (involving percolation_cluster_id)\n",
    "results = []\n",
    "\n",
    "# Test percolation_cluster_id vs poi_cluster_id\n",
    "result1 = calculate_chi2_percolation('percolation_cluster_id', 'poi_cluster_id', df)\n",
    "if result1 is not None:\n",
    "    results.append(result1)\n",
    "\n",
    "# Test percolation_cluster_id vs affinity_cluster_id\n",
    "result2 = calculate_chi2_percolation('percolation_cluster_id', 'affinity_cluster_id', df)\n",
    "if result2 is not None:\n",
    "    results.append(result2)\n",
    "\n",
    "# Calculate the result of the third test (not involving percolation_cluster_id)\n",
    "# Test poi_cluster_id vs affinity_cluster_id\n",
    "result3 = calculate_chi2_general('poi_cluster_id', 'affinity_cluster_id', df)\n",
    "if result3 is not None:\n",
    "    results.append(result3)\n",
    "\n",
    "# If there are results, save them to a CSV file\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('./chi-square_test_results_add_volumn_check.csv', index=False)\n",
    "    print(\"Chi-square test results have been saved to './chi-square_test_results_add_volumn_check.csv'\")\n",
    "else:\n",
    "    print(\"No tests were performed due to insufficient sample sizes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Correlation index calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Read the merged data\n",
    "df = pd.read_csv('./all_clusters.csv')\n",
    "\n",
    "# Define a function to calculate Cramér's V and only retain rows where percolation_cluster_id has 10 or more samples\n",
    "def calculate_cramers_v(var1, var2, df):\n",
    "    # Drop rows with missing values\n",
    "    df_clean = df.dropna(subset=[var1, var2])\n",
    "\n",
    "    # Only retain rows where percolation_cluster_id has 10 or more samples\n",
    "    df_filtered = df_clean[df_clean.groupby('percolation_cluster_id')['percolation_cluster_id'].transform('count') >= 10]\n",
    "\n",
    "    # If there is not enough data after filtering, return None\n",
    "    if df_filtered.empty:\n",
    "        print(f\"After filtering, there are no {var1} instances with 10 or more records for the test between {var1} and {var2}.\")\n",
    "        return None\n",
    "\n",
    "    # Construct a contingency table\n",
    "    contingency_table = pd.crosstab(df_filtered[var1], df_filtered[var2])\n",
    "\n",
    "    # Calculate chi-squared statistic\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "    # Calculate Cramér's V\n",
    "    n = contingency_table.sum().sum()  # Total number of samples\n",
    "    min_dim = min(contingency_table.shape) - 1  # Use the smaller dimension minus 1\n",
    "    cramers_v = np.sqrt(chi2 / (n * min_dim))\n",
    "\n",
    "    # Determine the strength of the association\n",
    "    if cramers_v < 0.1:\n",
    "        strength = \"None or very weak\"\n",
    "    elif cramers_v < 0.3:\n",
    "        strength = \"Weak\"\n",
    "    elif cramers_v < 0.5:\n",
    "        strength = \"Moderate\"\n",
    "    else:\n",
    "        strength = \"Strong\"\n",
    "\n",
    "    print(f\"Cramér's V between {var1} and {var2}: {cramers_v:.4f} (Strength: {strength})\")\n",
    "    return {\n",
    "        \"Test\": f\"{var1} vs {var2}\",\n",
    "        \"Cramér's V\": cramers_v,\n",
    "        \"Strength\": strength\n",
    "    }\n",
    "\n",
    "# List to store the results\n",
    "results = []\n",
    "\n",
    "# Calculate Cramér's V between percolation_cluster_id and poi_cluster_id\n",
    "cramers_v1 = calculate_cramers_v('percolation_cluster_id', 'poi_cluster_id', df)\n",
    "if cramers_v1 is not None:\n",
    "    results.append(cramers_v1)\n",
    "\n",
    "# Calculate Cramér's V between percolation_cluster_id and affinity_cluster_id\n",
    "cramers_v2 = calculate_cramers_v('percolation_cluster_id', 'affinity_cluster_id', df)\n",
    "if cramers_v2 is not None:\n",
    "    results.append(cramers_v2)\n",
    "\n",
    "# If there are results, save them to a CSV file\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('./cramers_v_results.csv', index=False)\n",
    "    print(\"Cramér's V results have been saved to './cramers_v_results.csv'\")\n",
    "else:\n",
    "    print(\"No results to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
